# 室内数据采集方案总结

## 项目目标
- 面向机器人仿真与任务生成，收集具有真实生活气息的室内图像。
- 场景需包含足够多可操作的物体，呈现“适度杂乱”，从而提供更多可能的机器人操作任务。

## 现有方案回顾

### 方案一：关键词抓取 + CLIP/VLM 筛选
- `crawler.py` 利用关键词批量抓取百度图片，并在 `filter_basic.py`、`filter_vlm.py` 中筛选。
- 当前 `filter_basic` 仅启用 indoor/outdoor 判别，杂乱度与物体数量约束默认关闭，导致大量价值不足的图片进入下一阶段。
- `filter_vlm` 能提高质量，但推理成本高、未缓存重复请求，阈值（score ≥ 0.6）仍会放行边界样本。

### 方案二：手动种子 + 以图搜图
- `search_by_images.py` 通过上传种子图获取相似结果，辅以 `remove_seed_duplicates.py` 做 dHash 去重。
- 现有 dHash 仅针对种子本身，相互之间缺乏跨候选对比；百度返回高度相似图较多，导致重复堆积。
- 数据源仍局限于百度，难以覆盖更多家居/工具/工作台等细分场景。

## 主要问题
- **初筛能力弱**：CLIP 阶段未执行杂乱度与对象数量判断，无法有效拦截“干净/空旷”的图片。
- **成本控制不足**：所有候选都进入 VLM 评估，缺少批量缓存与早期剔除策略。
- **重复度高**：dHash 仅对种子去重，缺乏跨批次、跨运行的相似度维护。
- **数据来源单一**：只依赖百度，真实可操作物体类型的覆盖度有限。

## 优化建议
- 重新标定 `filter_basic` 阈值：恢复杂乱度比较（moderate vs tidy/messy），默认开启 `object_count_min ≥ 8`，用小规模标注集验证。
- 在 VLM 前增加中间启发式：调用通用检测器（OWL-ViT/GroundingDINO）统计桌面物体、水平面，先过滤明显不合格样本。
- 扩展去重手段：结合 CLIP 向量，在 FAISS 里排重；同时引入多种感知哈希（pHash/dHash/aHash）对比历史图库。
- 拓展关键词与来源：针对“凌乱 办公 桌面”“车库 工作台 工具”等细分词组；尝试 RSS/博客/公寓租售网站等可深度翻页的垂直站点。
- 建立反馈迭代：让 VLM 输出的房间/物体标签反哺新查询词或裁剪局部区域作为后续种子。

## 更具前景的方案
- **多视角扫描合作**：与 Matterport 等室内扫描平台合作，获取可直接用于仿真的多视角全景或网格。
- **众包采集计划**：提供拍摄模板与物体清单，让贡献者上传真实家庭/工作台扫视视频，再通过 COLMAP/Gaussian Splatting 重建可操作场景。
- **垂直领域数据源**：重点抓取爱好者论坛、维修博客、厨房/工作室分享站点等天然富含可操作物体的来源。
- **CLIP 向量检索**：在大规模公开数据集（如 LAION 子集）上做向量搜索，先筛出潜在合格候选，再补抓原图。
- **仿真生成融合**：在真实背景上叠加任务相关的合成物体布局（NeRF/扩散模型），生成既真实又满足操作需求的混合图像。

